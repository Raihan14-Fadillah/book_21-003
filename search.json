[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quarto CRC Book",
    "section": "",
    "text": "Preface\nThis is a Quarto book."
  },
  {
    "objectID": "index.html#software-conventions",
    "href": "index.html#software-conventions",
    "title": "Quarto CRC Book",
    "section": "Software conventions",
    "text": "Software conventions\n\n1 + 1\n\n2\n\n\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "Quarto CRC Book",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nBlah, blah, blah…"
  },
  {
    "objectID": "laporan.html",
    "href": "laporan.html",
    "title": "1  Persiapan",
    "section": "",
    "text": "2 Bussiness Understanding\nDari Data Understanding diatas dapat disimpulkan bahwasannya: - Didalam data memiliki Missing Values - Didalam data juga terdapat outlier yang terdeteksi - Terdapat Fitur dengan tipe categorial yang harus diganti ke numerik - Beberapa fitur tidak terlalu penting - Terjadi Inbalancing pada data - fitur-fitur dalam dataset memiliki skala yang berbeda-beda\nMaka dari itu perlu dilakukan beberapa langkah preprocessing pada data seperti: - Penanganan Missing Value - Penanganan pada Outlier - Merubah fitur tipe categorial ke numerik - Melakukan seleksi fitur - Balancing Data agar jumlah kelas pada data menjadi seimbang\ndata = pd.read_csv(\"garmenBal.csv\")\n\nX = data.drop('Label', axis=1)\ny = data['Label']\n\nwith open('scaler_model.pkl', 'rb') as file:\n    scaler = pickle.load(file)\n\nX_normalized = scaler.transform(X)\n\nwith open('best_rf_model.pkl', 'rb') as file:\n    best_rf_model = pickle.load(file)\n\nX_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n\ny_pred = best_rf_model.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred, average='weighted')\nprecision = precision_score(y_test, y_pred, average='weighted')\nf1 = f1_score(y_test, y_pred, average='weighted')\n\nprint(f'Akurasi: {accuracy:.2%}')\nprint(f'Recall: {recall:.2%}')\nprint(f'Precision: {precision:.2%}')\nprint(f'F1 Score: {f1:.2%}')\n\nprint('\\nClassification Report:')\nprint(classification_report(y_test, y_pred))\n\nAkurasi: 100.00%\nRecall: 100.00%\nPrecision: 100.00%\nF1 Score: 100.00%\n\nClassification Report:\n              precision    recall  f1-score   support\n\n        High       1.00      1.00      1.00       165\n         Low       1.00      1.00      1.00       150\n      Medium       1.00      1.00      1.00       164\n\n    accuracy                           1.00       479\n   macro avg       1.00      1.00      1.00       479\nweighted avg       1.00      1.00      1.00       479"
  },
  {
    "objectID": "laporan.html#import-file",
    "href": "laporan.html#import-file",
    "title": "1  Persiapan",
    "section": "1.1 Import File",
    "text": "1.1 Import File\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\n%cd /content/drive/MyDrive/PSD_SMSTR_5/Project2-1/laporan\n\nMounted at /content/drive\n/content/drive/MyDrive/PSD_SMSTR_5/Project2-1/laporan"
  },
  {
    "objectID": "laporan.html#import-library",
    "href": "laporan.html#import-library",
    "title": "1  Persiapan",
    "section": "1.2 Import Library",
    "text": "1.2 Import Library\n\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nfrom IPython.display import display, Math\nfrom sympy import symbols, Eq\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import resample\nfrom sklearn.preprocessing import MinMaxScaler\nimport pickle\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier"
  },
  {
    "objectID": "laporan.html#import-data",
    "href": "laporan.html#import-data",
    "title": "1  Persiapan",
    "section": "1.3 Import Data",
    "text": "1.3 Import Data\n\ndf_review = pd.read_csv ('garmen.csv')\ndf_review.head()\n\n\n  \n    \n\n\n\n\n\n\ndate\nquarter\ndepartment\nday\nteam\ntargeted_productivity\nsmv\nwip\nover_time\nincentive\nidle_time\nidle_men\nno_of_style_change\nno_of_workers\nactual_productivity\nLabel\n\n\n\n\n0\n1/1/2015\nQuarter1\nsweing\nThursday\n8\n0.80\n26.16\n1108.0\n7080\n98\n0.0\n0\n0\n59.0\n0.940725\nHigh\n\n\n1\n1/1/2015\nQuarter1\nfinishing\nThursday\n1\n0.75\n3.94\nNaN\n960\n0\n0.0\n0\n0\n8.0\n0.886500\nHigh\n\n\n2\n1/1/2015\nQuarter1\nsweing\nThursday\n11\n0.80\n11.41\n968.0\n3660\n50\n0.0\n0\n0\n30.5\n0.800570\nHigh\n\n\n3\n1/1/2015\nQuarter1\nsweing\nThursday\n12\n0.80\n11.41\n968.0\n3660\n50\n0.0\n0\n0\n30.5\n0.800570\nHigh\n\n\n4\n1/1/2015\nQuarter1\nsweing\nThursday\n6\n0.80\n25.90\n1170.0\n1920\n50\n0.0\n0\n0\n56.0\n0.800382\nHigh"
  },
  {
    "objectID": "laporan.html#tujuan-proyek",
    "href": "laporan.html#tujuan-proyek",
    "title": "1  Persiapan",
    "section": "2.1 Tujuan Proyek",
    "text": "2.1 Tujuan Proyek\nMemprediksi atau mengukur produktivitas karyawan di industri garmen dengan menggunakan model prediksi. Tingkat produktivitas karyawan atau tim pada suatu hari atau periode tertentu dapat diperkirakan sebagai berikut:\n\nProduktivitas lebih rendah atau sama dengan 0.5 maka dikategorikan sebagai “low”\nProduktivitas di atas 0.5 dan kurang dari 0.8 dikategorikan sebagai “medium”\nProduktivitas 0.8 atau lebih dikategorikan sebagai “high”\n\nTujuan lainnya adalah mengidentifikasi faktor-faktor yang paling memengaruhi produktivitas karyawan. Ini dapat mencakup variabel seperti jumlah pekerja, waktu kerja tambahan (overtime), insentif, dan lainnya."
  },
  {
    "objectID": "laporan.html#deskripsi-fitur",
    "href": "laporan.html#deskripsi-fitur",
    "title": "1  Persiapan",
    "section": "2.2 Deskripsi Fitur",
    "text": "2.2 Deskripsi Fitur\n\ndate (Tanggal dalam format MM-DD-YYYY)\nday (Hari dalam seminggu)\nquarter (Sebagian dari bulan. Sebulan dibagi menjadi empat kuarter)\ndepartment (Departemen yang terkait dengan instance)\nteam_no (Nomor tim yang terkait dengan instance)\nno_of_workers (Jumlah pekerja dalam setiap tim)\nno_of_style_change (Jumlah perubahan gaya pada produk tertentu)\ntargeted_productivity (Produktivitas yang ditargetkan oleh Otoritas untuk setiap tim setiap hari)\nsmv (Standard Minute Value, yaitu waktu yang dialokasikan untuk suatu tugas)\nwip (Work in progress. Termasuk jumlah item yang belum selesai untuk produk)\nover_time (Mewakili jumlah lembur oleh setiap tim dalam menit)\nincentive (Mewakili jumlah insentif finansial (dalam BDT) yang memungkinkan atau memotivasi suatu tindakan tertentu)\nidle_time (Jumlah waktu ketika produksi terganggu karena beberapa alasan)\nidle_men (Jumlah pekerja yang menganggur karena gangguan produksi)\nactual_productivity (Persentase produktivitas aktual yang disampaikan oleh pekerja. Berkisar dari 0-1)"
  },
  {
    "objectID": "laporan.html#teknik-pengumpulan-data",
    "href": "laporan.html#teknik-pengumpulan-data",
    "title": "1  Persiapan",
    "section": "3.1 Teknik Pengumpulan Data",
    "text": "3.1 Teknik Pengumpulan Data\nStudi ini akan membahas produktivitas karyawan di industri garmen. Data dikumpulkan dari berbagai perusahaan garmen dan mencakup berbagai aspek seperti jumlah pekerja, waktu kerja tambahan (overtime), insentif, dan lainnya. Setiap entri menunjukkan tingkat produktivitas pada hari tertentu dan database akhir diekspor ke dalam satu lembar (.csv).\nJumlah Dataset sebanyak 1197 dengan rincian sebagai berikut: - Produktivitas tinggi (“High”) = 798 data - Produktivitas sedang (“Medium”) = 266 data - Produktivitas rendah (“Low”) = 133 data\nPertanyaan yang perlu diteliti lebih lanjut meliputi: - Apakah terdapat Missing Values pada data? - Apakah terdapat Outlier pada data? - Apakah proporsi dari setiap kelas pada data sudah seimbang atau inbalancing?"
  },
  {
    "objectID": "laporan.html#deskripsi-fitur-1",
    "href": "laporan.html#deskripsi-fitur-1",
    "title": "1  Persiapan",
    "section": "3.2 Deskripsi Fitur",
    "text": "3.2 Deskripsi Fitur\n\ndate (Tanggal dalam format MM-DD-YYYY): Tanggal pengumpulan data.\nday (Hari dalam seminggu): Hari dalam seminggu ketika data dikumpulkan.\nquarter (Sebagian dari bulan): Sebulan dibagi menjadi empat kuarter.\ndepartment (Departemen yang terkait dengan instance): Departemen tempat data dikumpulkan.\nteam_no (Nomor tim yang terkait dengan instance): Nomor tim yang terlibat dalam pengumpulan data.\nno_of_workers (Jumlah pekerja dalam setiap tim): Jumlah pekerja dalam tim yang terlibat dalam pengumpulan data.\nno_of_style_change (Jumlah perubahan gaya pada produk tertentu): Jumlah perubahan gaya yang dilakukan pada produk selama periode pengumpulan data.\ntargeted_productivity (Produktivitas yang ditargetkan oleh Otoritas untuk setiap tim setiap hari): Target produktivitas yang ditetapkan oleh manajemen untuk setiap tim setiap hari.\nsmv (Standard Minute Value, yaitu waktu yang dialokasikan untuk suatu tugas): Waktu standar yang dialokasikan untuk menyelesaikan suatu tugas.\nwip (Work in progress): Jumlah item yang belum selesai untuk produk.\nover_time (Mewakili jumlah lembur oleh setiap tim dalam menit): Jumlah waktu lembur yang dilakukan oleh setiap tim dalam menit.\nincentive (Mewakili jumlah insentif finansial (dalam BDT) yang memungkinkan atau memotivasi suatu tindakan tertentu): Jumlah insentif finansial yang diberikan kepada pekerja.\nidle_time (Jumlah waktu ketika produksi terganggu karena beberapa alasan): Jumlah waktu ketika produksi terhenti karena beberapa alasan.\nidle_men (Jumlah pekerja yang menganggur karena gangguan produksi): Jumlah pekerja yang tidak bekerja karena gangguan produksi.\nactual_productivity (Persentase produktivitas aktual yang disampaikan oleh pekerja. Berkisar dari 0-1): Tingkat produktivitas aktual yang dicapai oleh pekerja. Nilai ini berkisar dari 0 hingga 1.\n\n\ndf_review.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1197 entries, 0 to 1196\nData columns (total 16 columns):\n #   Column                 Non-Null Count  Dtype  \n---  ------                 --------------  -----  \n 0   date                   1197 non-null   object \n 1   quarter                1197 non-null   object \n 2   department             1197 non-null   object \n 3   day                    1197 non-null   object \n 4   team                   1197 non-null   int64  \n 5   targeted_productivity  1197 non-null   float64\n 6   smv                    1197 non-null   float64\n 7   wip                    691 non-null    float64\n 8   over_time              1197 non-null   int64  \n 9   incentive              1197 non-null   int64  \n 10  idle_time              1197 non-null   float64\n 11  idle_men               1197 non-null   int64  \n 12  no_of_style_change     1197 non-null   int64  \n 13  no_of_workers          1197 non-null   float64\n 14  actual_productivity    1197 non-null   float64\n 15  Label                  1197 non-null   object \ndtypes: float64(6), int64(5), object(5)\nmemory usage: 149.8+ KB\n\n\n\ndf_review.columns\n\nIndex(['date', 'quarter', 'department', 'day', 'team', 'targeted_productivity',\n       'smv', 'wip', 'over_time', 'incentive', 'idle_time', 'idle_men',\n       'no_of_style_change', 'no_of_workers', 'actual_productivity', 'Label'],\n      dtype='object')"
  },
  {
    "objectID": "laporan.html#tipe-data",
    "href": "laporan.html#tipe-data",
    "title": "1  Persiapan",
    "section": "3.3 Tipe Data",
    "text": "3.3 Tipe Data\nTerdapat beberapa Tipe Data yang terdapat didalam dataset, diantaranya - Tipe Data Rasio\n\n\ndate\nquarter\nteam_no\nno_of_workers\nno_of_style_change\ntargeted_productivity\nsmv\nwip\nover_time\nincentive\nidle_time\nidle_men\n\n\n\nTipe Data Interval &gt; - day &gt; - department &gt; - actual_productivity\n\nBanyak data dalam masing-masing kelasnya\n\ndf_review['actual_productivity'].unique()\n\narray([0.94072542, 0.8865    , 0.80057049, 0.80038194, 0.800125  ,\n       0.75516667, 0.75368348, 0.75309753, 0.75042783, 0.72112696,\n       0.71220525, 0.7070459 , 0.70591667, 0.67666667, 0.59305556,\n       0.54072917, 0.52118   , 0.43632639, 0.98802469, 0.98788044,\n       0.95627083, 0.94527778, 0.90291667, 0.80072531, 0.80032294,\n       0.80031864, 0.80023729, 0.80014865, 0.78729969, 0.78244792,\n       0.75024303, 0.7018125 , 0.70013404, 0.69996522, 0.62833333,\n       0.6253125 , 0.99138889, 0.93164583, 0.91522917, 0.87971448,\n       0.86167901, 0.85056949, 0.85043644, 0.85034513, 0.80059806,\n       0.80023784, 0.8000302 , 0.79210417, 0.75922839, 0.75034846,\n       0.68270833, 0.66760417, 0.60343218, 0.34583333, 0.96105903,\n       0.93951389, 0.89366319, 0.87539062, 0.82083333, 0.80441667,\n       0.80068437, 0.80025096, 0.80024601, 0.80007652, 0.763375  ,\n       0.75927083, 0.7504    , 0.66458333, 0.60002874, 0.96678135,\n       0.93649621, 0.89916667, 0.88868687, 0.85814394, 0.85050231,\n       0.80964015, 0.80590909, 0.80059447, 0.80027383, 0.80014097,\n       0.80012872, 0.80007657, 0.75054546, 0.75005785, 0.68106061,\n       0.64998328, 0.61625   , 0.95142046, 0.8805303 , 0.85013677,\n       0.83      , 0.82718654, 0.81337121, 0.80464015, 0.80034377,\n       0.80024675, 0.8       , 0.70048083, 0.66651515, 0.41211983,\n       0.33011364, 0.94768939, 0.9199054 , 0.90021572, 0.89172348,\n       0.85018182, 0.83575758, 0.82135417, 0.80049725, 0.80010714,\n       0.80002493, 0.77979167, 0.73598485, 0.71262626, 0.51560606,\n       0.34995139, 0.23370548, 0.985     , 0.93034038, 0.91158974,\n       0.85117411, 0.84695076, 0.81742424, 0.81710227, 0.80102821,\n       0.80034644, 0.8001171 , 0.75009835, 0.67324528, 0.67007576,\n       0.62888258, 0.38800781, 0.33797349, 0.93532197, 0.92564394,\n       0.87306818, 0.82829546, 0.69018282, 0.66808712, 0.65359848,\n       0.60913826, 0.60022985, 0.59734849, 0.59043561, 0.4731348 ,\n       0.45297963, 0.95515151, 0.9422138 , 0.90545454, 0.85052217,\n       0.80956439, 0.80018182, 0.725     , 0.68855756, 0.65004078,\n       0.64998056, 0.64810606, 0.64057765, 0.35063299, 0.24625   ,\n       0.9520202 , 0.91276667, 0.90126263, 0.85025253, 0.70557658,\n       0.60127841, 0.58230103, 0.52681035, 0.5003808 , 0.35020649,\n       0.93460744, 0.90808081, 0.90014481, 0.86458333, 0.8375947 ,\n       0.80031343, 0.70009556, 0.66732954, 0.60036969, 0.49998033,\n       0.35003125, 0.33235931, 0.31120746, 0.24731602, 0.98863636,\n       0.95311005, 0.88426136, 0.86065341, 0.85041563, 0.80003139,\n       0.70006035, 0.68929924, 0.66068329, 0.65013095, 0.60691288,\n       0.60029177, 0.50002507, 0.49999889, 0.98719697, 0.98090909,\n       0.97462121, 0.82680303, 0.77011398, 0.7005417 , 0.67556818,\n       0.66183712, 0.65019865, 0.60027327, 0.46575758, 0.45201254,\n       0.31385281, 0.85279356, 0.83838384, 0.80484848, 0.80001501,\n       0.70009416, 0.69204546, 0.66225589, 0.65041673, 0.65029958,\n       0.6502435 , 0.63986742, 0.6000627 , 0.58204546, 0.40324216,\n       0.23579545, 0.97727273, 0.96410606, 0.95890151, 0.80035877,\n       0.8001626 , 0.7938447 , 0.75051756, 0.75006805, 0.75006275,\n       0.75005736, 0.70017039, 0.68380682, 0.65006644, 0.57646039,\n       0.54996943, 0.53839962, 0.40954546, 0.35021836, 1.03357008,\n       0.80026149, 0.75003797, 0.7500319 , 0.72830303, 0.7000638 ,\n       0.50029042, 0.40033279, 0.36266667, 0.97852564, 0.91220211,\n       0.90055628, 0.85041051, 0.82714744, 0.80043654, 0.80041574,\n       0.80002056, 0.75817308, 0.75034483, 0.70002977, 0.60017284,\n       0.59487179, 0.52023765, 0.5051282 , 0.50024134, 0.47076923,\n       0.95763889, 0.94070106, 0.84998377, 0.80030279, 0.80019199,\n       0.75016237, 0.74290124, 0.70025078, 0.67021605, 0.64966222,\n       0.62682292, 0.60043643, 0.60041361, 0.55550013, 0.50054754,\n       0.4605787 , 0.39774306, 0.32740741, 0.96666667, 0.93724242,\n       0.91052189, 0.90064806, 0.90032111, 0.89602273, 0.89545454,\n       0.87058081, 0.85858586, 0.80064381, 0.80062987, 0.80053714,\n       0.80035194, 0.75007932, 0.7500412 , 0.65151515, 0.60012522,\n       0.57831439, 0.34998951, 0.26117424, 0.97379679, 0.97007576,\n       0.96178451, 0.85022378, 0.80090961, 0.80051331, 0.80038636,\n       0.74918831, 0.70043672, 0.65040752, 0.61818182, 0.59114168,\n       0.50006192, 0.32954545, 1.05962121, 0.99779221, 0.96369949,\n       0.95919192, 0.91037879, 0.85031268, 0.80003402, 0.80002351,\n       0.76929293, 0.75003145, 0.70061442, 0.64630682, 0.60014336,\n       0.35006699, 1.00023041, 0.97952778, 0.940625  , 0.92638889,\n       0.90012976, 0.861875  , 0.84545833, 0.82355556, 0.80354167,\n       0.80026322, 0.788     , 0.77815   , 0.70038621, 0.70016471,\n       0.65030714, 0.62282812, 0.6225    , 0.50003535, 0.37046657,\n       0.97755556, 0.9456    , 0.90222222, 0.85053214, 0.85036207,\n       0.84053333, 0.80053448, 0.80048968, 0.75555556, 0.7505931 ,\n       0.75028333, 0.72263889, 0.55333333, 0.50056731, 0.46769327,\n       0.43799534, 0.40635417, 0.28533333, 0.259375  , 0.989     ,\n       0.95018596, 0.9008    , 0.899     , 0.87755208, 0.85695   ,\n       0.85366667, 0.85017011, 0.80047373, 0.77333333, 0.75064667,\n       0.63466667, 0.60059761, 0.50011768, 0.4925    , 0.48792   ,\n       1.00045747, 0.97186667, 0.9202369 , 0.90053707, 0.85061053,\n       0.65676374, 0.65014815, 0.60071061, 0.38883036, 0.28698457,\n       1.0115625 , 1.0006713 , 1.00040205, 0.9504386 , 0.89219444,\n       0.85011396, 0.84506944, 0.75045066, 0.70266667, 0.70050893,\n       0.65100707, 0.46682121, 0.41155357, 0.31416667, 1.00060228,\n       0.99427083, 0.9001584 , 0.90014152, 0.80923611, 0.80040196,\n       0.80039322, 0.79996322, 0.74044444, 0.70039815, 0.70035455,\n       0.56197917, 0.50459649, 0.50080172, 0.29530774, 0.28033333,\n       0.26097879, 1.00141667, 1.00001855, 0.99999524, 0.99485   ,\n       0.97697917, 0.94998161, 0.91995454, 0.80043462, 0.80025902,\n       0.77822222, 0.70051357, 0.70018458, 0.58646546, 0.54151786,\n       0.5375    , 0.49541667, 0.41517241, 1.05028058, 0.96675926,\n       0.92918333, 0.91576667, 0.90014725, 0.70071042, 0.70061207,\n       0.70027885, 0.70013509, 0.68755556, 0.65083481, 0.53166667,\n       0.35070642, 1.00044602, 0.99992424, 0.9425    , 0.90666667,\n       0.8471    , 0.80061268, 0.77158333, 0.70007903, 0.56221264,\n       0.52284483, 0.50072013, 0.49654971, 1.05066667, 0.90013569,\n       0.89911111, 0.87008333, 0.84583333, 0.75052012, 0.75002778,\n       0.71576667, 0.66227011, 0.60022419, 0.54565767, 0.44791667,\n       0.36531871, 0.92868056, 0.89306667, 0.89155556, 0.87555556,\n       0.84088889, 0.80035521, 0.75065101, 0.70061823, 0.61020833,\n       0.60741667, 0.56825959, 0.35553448, 0.35325965, 1.05796296,\n       0.96201667, 0.90050904, 0.90047782, 0.888125  , 0.80016117,\n       0.79000324, 0.75064815, 0.70711111, 0.69770833, 0.61251716,\n       0.35030172, 0.272     , 1.00488889, 0.90063244, 0.90047076,\n       0.89998406, 0.8008    , 0.79675556, 0.75079701, 0.75035613,\n       0.70377083, 0.6895    , 0.39354885, 1.03315556, 1.02      ,\n       1.00034493, 1.00006579, 0.994375  , 0.91203704, 0.87      ,\n       0.85036458, 0.80094747, 0.80014414, 0.75040623, 0.71441049,\n       0.70058841, 0.61836111, 0.60007051, 0.54175   , 0.53690175,\n       0.50790323, 1.10048392, 1.09663333, 0.83866667, 0.75548611,\n       0.75079944, 0.68801768, 0.664875  , 0.65666667, 0.63771186,\n       0.60194444, 0.58      , 0.53567797, 0.50012336, 0.49788506,\n       0.46340395, 0.441392  , 0.92927778, 0.80088889, 0.80037492,\n       0.79620833, 0.75039216, 0.725625  , 0.70020613, 0.602     ,\n       0.60044751, 0.55725245, 0.48333333, 0.23804167, 1.1204375 ,\n       1.108125  , 0.87644444, 0.80080631, 0.76083333, 0.72256863,\n       0.71533333, 0.70063277, 0.7005731 , 0.68159804, 0.65022372,\n       0.60520833, 0.60416667, 0.59862745, 0.47571839, 0.4321229 ,\n       0.28704167, 0.28305449, 0.96043333, 0.80224332, 0.80098039,\n       0.80031237, 0.72233333, 0.70045989, 0.62941667, 0.62197175,\n       0.56597222, 0.35542803, 0.32996488, 0.258     , 0.92754167,\n       0.91375   , 0.9025    , 0.7866    , 0.75062135, 0.74916667,\n       0.7008882 , 0.70061403, 0.70060345, 0.65343137, 0.650134  ,\n       0.60098291, 0.58604167, 0.5814    , 0.36107143, 0.30211735,\n       0.9918    , 0.93686111, 0.919125  , 0.8211125 , 0.80027969,\n       0.75053268, 0.73464583, 0.70009573, 0.671875  , 0.64025   ,\n       0.54979167, 0.32813158, 0.30357447, 0.2565    , 0.25139925,\n       0.81640625, 0.80071149, 0.80047051, 0.80009402, 0.79998285,\n       0.7858642 , 0.73327778, 0.710125  , 0.70054044, 0.7       ,\n       0.68402778, 0.67213542, 0.63861438, 0.63135417, 0.61114054,\n       0.60958333, 0.58531579, 0.24941667, 0.8721    , 0.8319375 ,\n       0.8300625 , 0.80555556, 0.80000295, 0.78375   , 0.753525  ,\n       0.72734954, 0.70060526, 0.6721408 , 0.62701118, 0.62657778,\n       0.456875  , 0.38579167, 0.30750146, 0.28395833, 0.95579167,\n       0.93041667, 0.87115   , 0.80013725, 0.75077012, 0.75029394,\n       0.700623  , 0.70036207, 0.60128   , 0.41791667, 0.3715625 ,\n       0.36871875, 0.35645833, 0.81138889, 0.80007184, 0.79145833,\n       0.75072733, 0.75043727, 0.75017699, 0.72693333, 0.70051852,\n       0.7002568 , 0.5046875 , 0.47110849, 0.325     , 0.26821429,\n       0.97081667, 0.90296296, 0.90083333, 0.89955556, 0.80080864,\n       0.80011582, 0.75050357, 0.7502069 , 0.70006981, 0.70005833,\n       0.65854167, 0.59879234, 0.58113095, 0.440375  , 0.41083333,\n       0.9217037 , 0.92160494, 0.80051667, 0.76884722, 0.75047368,\n       0.7503719 , 0.70025177, 0.66237931, 0.59061728, 0.5565625 ,\n       0.49561751, 0.44996491, 0.4078125 , 0.37889515, 0.37659722,\n       0.271875  , 0.80077902, 0.80026082, 0.75071698, 0.75042593,\n       0.75039551, 0.7002366 , 0.70021111, 0.55040351, 0.55034971,\n       0.50025805, 0.93635556, 0.81361111, 0.75075   , 0.70744643,\n       0.70001988, 0.68355061, 0.68243304, 0.67308333, 0.60023977,\n       0.585     , 0.57951149, 0.44872222, 0.44708333, 0.35041667,\n       0.92885   , 0.86037037, 0.80687917, 0.80057953, 0.8004    ,\n       0.80030921, 0.80014981, 0.75025487, 0.70090357, 0.70013604,\n       0.63236111, 0.60765432, 0.53791944, 0.34236111, 0.99953333,\n       0.80070175, 0.80056609, 0.80033333, 0.75021255, 0.70277778,\n       0.70065965, 0.69998442, 0.63604938, 0.56737778, 0.55543056,\n       0.46319444, 0.35444444, 0.30933333, 0.30277037, 0.93916667,\n       0.88592593, 0.83375   , 0.80605833, 0.80005576, 0.79997586,\n       0.75065172, 0.70042414, 0.68488889, 0.59208333, 0.5403125 ,\n       0.43326316, 0.40414493, 0.33214647, 0.98098485, 0.950625  ,\n       0.92729167, 0.86888889, 0.812625  , 0.81011111, 0.80053498,\n       0.75005085, 0.700422  , 0.60009914, 0.453125  , 0.36605352,\n       0.26369382, 0.85052059, 0.850045  , 0.82544444, 0.80575   ,\n       0.80074655, 0.80057895, 0.8000345 , 0.7975    , 0.74998712,\n       0.65708333, 0.65024031, 0.59074074, 0.528125  , 0.50052809,\n       0.40896035, 0.95194444, 0.94555556, 0.92907407, 0.89060417,\n       0.884     , 0.85791667, 0.85008421, 0.85007069, 0.80051107,\n       0.75520833, 0.70010606, 0.60103709, 0.60052857, 0.5000339 ,\n       0.4509375 , 0.44104167, 0.960625  , 0.86434259, 0.85044615,\n       0.85042689, 0.841     , 0.80084242, 0.79541667, 0.7953875 ,\n       0.79456667, 0.70051622, 0.6825    , 0.65096228, 0.65042143,\n       0.60004068, 0.50061091, 0.47729167, 0.2640625 , 0.92      ,\n       0.90939167, 0.90006102, 0.89444444, 0.881575  , 0.88075417,\n       0.82166667, 0.75822917, 0.750608  , 0.741     , 0.70050526,\n       0.70024649, 0.70005185, 0.65004407, 0.63040292, 0.560625  ,\n       0.39875   , 0.92283951, 0.87402778, 0.81927083, 0.81330903,\n       0.78663194, 0.75885   , 0.75034733, 0.75014074, 0.7005569 ,\n       0.65059649, 0.625625  , 0.50588889, 0.39472222])\n\n\n\ndf_review.actual_productivity.value_counts()\n\n0.800402    24\n0.971867    12\n0.850137    12\n0.750651    11\n0.850502    11\n            ..\n0.800034     1\n0.800024     1\n0.769293     1\n0.750031     1\n0.394722     1\nName: actual_productivity, Length: 879, dtype: int64"
  },
  {
    "objectID": "laporan.html#identifikasi-missing-value",
    "href": "laporan.html#identifikasi-missing-value",
    "title": "1  Persiapan",
    "section": "3.4 Identifikasi Missing Value",
    "text": "3.4 Identifikasi Missing Value\n\ndf_review.isnull().sum()\n\ndate                       0\nquarter                    0\ndepartment                 0\nday                        0\nteam                       0\ntargeted_productivity      0\nsmv                        0\nwip                      506\nover_time                  0\nincentive                  0\nidle_time                  0\nidle_men                   0\nno_of_style_change         0\nno_of_workers              0\nactual_productivity        0\nLabel                      0\ndtype: int64"
  },
  {
    "objectID": "laporan.html#visualisasi-data",
    "href": "laporan.html#visualisasi-data",
    "title": "1  Persiapan",
    "section": "3.5 Visualisasi Data",
    "text": "3.5 Visualisasi Data\n\n#distribution data\ndf_review.hist(figsize=(14, 14))\nplt.show()"
  },
  {
    "objectID": "laporan.html#identifikasi-outlier",
    "href": "laporan.html#identifikasi-outlier",
    "title": "1  Persiapan",
    "section": "3.6 Identifikasi Outlier",
    "text": "3.6 Identifikasi Outlier\n\ndef detect_outliers_zscore(data, threshold=3):\n    numerical_data = data.select_dtypes(include=[np.number])\n    z_scores = np.abs(stats.zscore(numerical_data))\n    outliers = np.where(z_scores &gt; threshold)\n    return outliers[0]\n\noutliers = detect_outliers_zscore(df_review)\nprint(\"Outliers:\", len(outliers))\n\nOutliers: 107"
  },
  {
    "objectID": "laporan.html#menentukan-produktivitas-highmediumlow",
    "href": "laporan.html#menentukan-produktivitas-highmediumlow",
    "title": "1  Persiapan",
    "section": "3.7 Menentukan Produktivitas High/Medium/Low",
    "text": "3.7 Menentukan Produktivitas High/Medium/Low\nTerdapat Tips untuk menangani masalah regresi maka dapat menetapkan batas produktivitas karyawan dimana, jika:\n\nProduktivitas karyawan lebih besar sama dengan 0.8 maka dinyatakan “high”\nProduktivitas karyawan di atas 0.5 dan kurang dari 0.8 maka dinyatakan “medium”\nProduktivitas karyawan lebih rendah atau sama dengan 0.5 maka dinyatakan “low”\n\n\ndata = pd.read_csv(\"garments_worker_productivity.csv\")\n\ndef label_productivity(row):\n    if row['actual_productivity'] &lt; 0.5:\n        return 'Low'\n    elif 0.7 &lt;= row['actual_productivity'] &lt; 0.8:\n        return 'Medium'\n    else:\n        return 'High'\n\ntarget = data['Label'] = data.apply(label_productivity, axis=1)"
  },
  {
    "objectID": "laporan.html#identifikasi-proporsi-jumlah-kelas-data",
    "href": "laporan.html#identifikasi-proporsi-jumlah-kelas-data",
    "title": "1  Persiapan",
    "section": "3.8 Identifikasi Proporsi Jumlah Kelas Data",
    "text": "3.8 Identifikasi Proporsi Jumlah Kelas Data\n\ntarget.value_counts()\n\nHigh      798\nMedium    266\nLow       133\ndtype: int64"
  },
  {
    "objectID": "laporan.html#penanganan-missing-value",
    "href": "laporan.html#penanganan-missing-value",
    "title": "1  Persiapan",
    "section": "4.1 Penanganan Missing Value",
    "text": "4.1 Penanganan Missing Value\n\nMembaca Data: Data dibaca dari file CSV dan dimuat ke dalam DataFrame data.\nGrouping dan Menghitung Rata-Rata: Data dikelompokkan berdasarkan kolom ‘Label’ menggunakan groupby(). Rata-rata untuk setiap kelompok dihitung dengan mean().\nPenanganan Missing Value: Nilai-nilai yang hilang diisi dengan nilai rata-rata dari kelompok yang sesuai menggunakan: data = data.apply(lambda row: row.fillna(mean_values.loc[row[’Label’]]), axis=1)\nMenyimpan Data yang Diperbarui: DataFrame yang sudah diperbarui disimpan ke dalam file CSV baru “garmenMis.csv” tanpa menyertakan indeks DataFrame.\n\n\ndata = pd.read_csv(\"garmen.csv\")\ngrouped_data = data.groupby('Label')\nmean_values = grouped_data.mean()\ndata = data.apply(lambda row: row.fillna(mean_values.loc[row['Label']]), axis=1)\ndata.to_csv(\"garmenMis.csv\", index=False)\n\nFutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n  mean_values = grouped_data.mean()"
  },
  {
    "objectID": "laporan.html#penanganan-pada-outlier",
    "href": "laporan.html#penanganan-pada-outlier",
    "title": "1  Persiapan",
    "section": "4.2 Penanganan pada outlier",
    "text": "4.2 Penanganan pada outlier\n\nPemisahan Fitur Numerik dan Kategorikal: &gt; - numerical_data: Fitur-fitur numerik dipilih menggunakan select_dtypes. &gt; - categorical_data: Fitur-fitur kategorikal dipilih menggunakan select_dtypes.\nPerhitungan Z-Score: Z-scores dihitung untuk setiap elemen dalam numerical_data menggunakan rumus: \\[Z = \\frac{X - \\mu}{\\sigma}\\] μ adalah rata-rata dan σ adalah deviasi standar.\nIdentifikasi Outlier: Outlier diidentifikasi dengan mengevaluasi apakah setidaknya satu nilai dalam setiap baris melebihi batas ambang (threshold).\nPenghapusan Outlier: Baris-baris yang mengandung outlier dihapus menggunakan bitwise negation.\nOutput Hasil: DataFrame yang sudah dihapus outlier dikembalikan sebagai hasil dari fungsi.\n\n\nimport numpy as np\nfrom scipy import stats\n\ndef remove_outliers_zscore(data, threshold=3):\n    numerical_data = data.select_dtypes(include=[np.number])\n    categorical_data = data.select_dtypes(exclude=[np.number])\n    z_scores = np.abs(stats.zscore(numerical_data, axis=0))\n    numerical_outliers = np.any(z_scores &gt; threshold, axis=1)\n    data = data[~numerical_outliers]\n    return data\n\ndata_without_outliers = remove_outliers_zscore(df_review)\nprint(\"Data tanpa outlier:\", len(data_without_outliers))\n\nData tanpa outlier: 1099"
  },
  {
    "objectID": "laporan.html#merubah-tipe-data-kategorial-ke-numerik",
    "href": "laporan.html#merubah-tipe-data-kategorial-ke-numerik",
    "title": "1  Persiapan",
    "section": "4.3 Merubah tipe data Kategorial ke Numerik",
    "text": "4.3 Merubah tipe data Kategorial ke Numerik\n\nMengubah Tipe Data Kategorial ke Numerik: Menggunakan LabelEncoder untuk mengonversi nilai-nilai kategorial menjadi representasi numerik. Contoh: ’quarter’→[0,1,2,…]\nEkstraksi Informasi Waktu dari Kolom Tanggal: Mengubah kolom ‘date’ menjadi tipe data datetime. Mengekstrak informasi waktu seperti bulan (‘month’), hari dalam bulan (‘dayNum’), dan tahun (‘year’) menggunakan atribut dt dari tipe data datetime. Menghapus kolom ‘date’ karena informasi waktu sudah diekstrak. Mengatur urutan kolom dengan memindahkan kolom waktu ke depan.\n\n\ndata = pd.read_csv(\"garmenMis.csv\")\nlabel_encoder = LabelEncoder()\ndata['quarter'] = label_encoder.fit_transform(data['quarter'])\ndata['department'] = label_encoder.fit_transform(data['department'])\ndata['day'] = label_encoder.fit_transform(data['day'])\ndata['team'] = label_encoder.fit_transform(data['team'])\ndata.to_csv(\"garmenEnc.csv\", index=False)\n\n\ndata = pd.read_csv(\"garmenEnc.csv\")\ndata['date'] = pd.to_datetime(data['date'])\ndata['month'] = data['date'].dt.month\ndata['dayNum'] = data['date'].dt.day\ndata['year'] = data['date'].dt.year\ndata = data.drop(columns=['date'])\ndata = data[['month', 'dayNum', 'year'] + [col for col in data if col not in ['year', 'month', 'dayNum']]]\ndata.to_csv(\"garmenSpe.csv\", index=False)"
  },
  {
    "objectID": "laporan.html#seleksi-fitur",
    "href": "laporan.html#seleksi-fitur",
    "title": "1  Persiapan",
    "section": "4.4 Seleksi Fitur",
    "text": "4.4 Seleksi Fitur\n\nAnalisis Chi-Square dan Visualisasi: Data dibaca dari file “garmenSpe.csv”. Fitur-fitur dan label diinisialisasi. Objek SelectKBest diinisialisasi dengan metode skor Chi-Square untuk menghitung skor untuk semua fitur. \\[\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\\] Di mana:\n\n\n\nOi​: Frekuensi observasi\n\n\n\n\nEi​: Frekuensi yang diharapkan\n\n\n\n\nTransformasi data fitur dilakukan dengan fit_transform. Skor Chi-Square untuk setiap fitur diambil. Visualisasi dilakukan dengan diagram batang menunjukkan skor Chi-Square untuk setiap fitur.\n\n\n\nSeleksi dan Simpan Fitur yang Dipilih: Data dibaca kembali dari file “garmenSpe.csv”. Objek SelectKBest diinisialisasi dengan memilih 7 fitur terbaik menggunakan parameter k=7. Transformasi data fitur dilakukan dengan fit_transform. Fitur yang terpilih diambil menggunakan get_support(). DataFrame yang berisi fitur-fitur terpilih dan label disimpan ke dalam file “garmenSel.csv”.\n\n\ndata = pd.read_csv(\"garmenSpe.csv\")\nX = data.drop(columns=['Label'])\ny = data['Label']\nk_best = SelectKBest(score_func=chi2, k='all')\nX_new = k_best.fit_transform(X, y)\nselected_features = X.columns[k_best.get_support()]\nselected_data = pd.DataFrame(X_new, columns=selected_features)\nselected_data['Label'] = data['Label']\nscores = k_best.scores_\nplt.bar(range(len(selected_features)), scores)\nplt.xticks(range(len(selected_features)), selected_features, rotation='vertical')\nplt.xlabel('Fitur')\nplt.ylabel('Chi-square Score')\nplt.title('Ranking Fitur dengan Chi-Square Score')\nplt.show()\n\n\n\n\n\ndata = pd.read_csv(\"garmenSpe.csv\")\nX = data.drop(columns=['Label'])\ny = data['Label']\nk_best = SelectKBest(score_func=chi2, k=7)\nX_new = k_best.fit_transform(X, y)\nselected_features = X.columns[k_best.get_support()]\nselected_data = data[selected_features]\nselected_data['Label'] = data['Label']\nselected_data.to_csv(\"garmenSel.csv\", index=False)\n\nSettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  selected_data['Label'] = data['Label']"
  },
  {
    "objectID": "laporan.html#balancing",
    "href": "laporan.html#balancing",
    "title": "1  Persiapan",
    "section": "4.5 Balancing",
    "text": "4.5 Balancing\n\nPembacaan Data dan Pembagian Kelas: Data awal dibaca dari file “garmenSel.csv”. Data dibagi menjadi tiga kelompok berdasarkan kelas target: ‘High’, ‘Medium’, dan ‘Low’.\nPenyesuaian Ukuran Kelas Minoritas dengan Oversampling: Jumlah sampel dari kelas mayoritas (‘High’) diambil sebagai referensi. Kelas minoritas (‘Medium’ dan ‘Low’) dioversampling menggunakan metode resample dengan parameter replace=True untuk pengambilan sampel dengan penggantian, dan n_samples menentukan jumlah sampel yang diambil.\nPenggabungan Data yang Telah Disesuaikan dan Penyimpanan: Data yang telah dioversampling digabungkan menjadi satu DataFrame. DataFrame yang telah disesuaikan disimpan ke dalam file “garmenBal.csv”.\nMenampilkan Distribusi Kelas yang Telah Disesuaikan: Setelah proses oversampling, distribusi kelas baru dicetak untuk memastikan bahwa kelas sekarang memiliki jumlah sampel yang seimbang.\n\n\ndata = pd.read_csv(\"garmenSel.csv\")\nhigh_class = data[data['Label'] == 'High']\nmedium_class = data[data['Label'] == 'Medium']\nlow_class = data[data['Label'] == 'Low']\nn_samples = len(high_class)\nmedium_class_oversampled = resample(medium_class, replace=True, n_samples=n_samples, random_state=42)\nlow_class_oversampled = resample(low_class, replace=True, n_samples=n_samples, random_state=42)\nbalanced_data = pd.concat([high_class, medium_class_oversampled, low_class_oversampled])\nbalanced_data.to_csv(\"garmenBal.csv\", index=False)\n\n\nimport pandas as pd\ndata = pd.read_csv(\"garmenBal.csv\")\nlabel_counts = data['Label'].value_counts()\nprint(label_counts)\n\nHigh      798\nMedium    798\nLow       798\nName: Label, dtype: int64"
  },
  {
    "objectID": "laporan.html#normalisasi",
    "href": "laporan.html#normalisasi",
    "title": "1  Persiapan",
    "section": "4.6 Normalisasi",
    "text": "4.6 Normalisasi\nNormalisasi dilakukan dengan menggunakan Minmax. Normalisasi Minmax dipilih untuk mengubah rentang nilai fitur menjadi skala yang sama. Ini penting karena beberapa algoritma pembelajaran mesin seperti K-Nearest Neighbors (KNN), Random Forest, SVM dan Neural Networks bekerja lebih baik jika semua fitur memiliki rentang nilai yang sama.\nRumus Min-Max Scaling: \\[X_{\\text{normalized}} = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}}\\] &gt;&gt;Di mana:\n\n\nXnormalized​: Nilai fitur yang telah dinormalisasi\n\n\n\n\nX: Nilai asli fitur\n\n\n\n\nXmin​: Nilai minimum fitur\n\n\n\n\nXmax​: Nilai maksimum fitur\n\n\nContoh Perhitungan dengan menerapkan rumus Min-Max diatas:\n\n\n\nHari\nProduktivitas\nProduktivitas Normalisasi\n\n\n\n\n1\n100\n0\n\n\n2\n200\n0.25\n\n\n3\n300\n0.5\n\n\n4\n400\n0.75\n\n\n5\n500\n1\n\n\n\nLangkah-Langkah Normalisasi 1. Pembacaan Data: Data awal dibaca dari file “garmenBal.csv”. 2. Pemisahan Fitur dan Label: Fitur-fitur disimpan dalam variabel X. Label disimpan dalam variabel y. 3. Normalisasi Menggunakan Min-Max Scaling: Objek MinMaxScaler diinisialisasi. Metode fit_transform() digunakan untuk mentransformasikan nilai-nilai fitur ke dalam rentang [0, 1] dengan mengurangkan nilai minimum dan membagi dengan selisih antara nilai maksimum dan minimum.\n\nPenyimpanan Model Scaler: Model scaler (MinMaxScaler) disimpan ke dalam file ‘scaler_model.pkl’ menggunakan modul pickle. Ini memungkinkan untuk menggunakan model scaler yang sama pada data baru yang akan diprediksi.\n\n\ndata = pd.read_csv(\"garmenBal.csv\")\nX = data.drop('Label', axis=1)\ny = data['Label']\nscaler = MinMaxScaler()\nX_normalized = scaler.fit_transform(X)\nwith open('scaler_model.pkl', 'wb') as file:\n    pickle.dump(scaler, file)"
  },
  {
    "objectID": "laporan.html#perbandingan-metode",
    "href": "laporan.html#perbandingan-metode",
    "title": "1  Persiapan",
    "section": "5.1 Perbandingan Metode",
    "text": "5.1 Perbandingan Metode\n\nPembacaan Data: Data dibaca dari file “garmenBal.csv”.\nPemisahan Fitur dan Label: Fitur-fitur disimpan dalam variabel X. Label disimpan dalam variabel y.\nPemulihan Model Scaler: Model scaler yang telah disimpan sebelumnya dibaca kembali menggunakan modul pickle.\nPembagian Data dan Normalisasi: Data dibagi menjadi set pelatihan dan pengujian.\nFitur-fitur dinormalisasi menggunakan model scaler yang telah dipulihkan. Inisialisasi Model Klasifikasi: Beberapa model klasifikasi diinisialisasi, termasuk Decision Tree, Random Forest, Logistic Regression, SVM, dan K-Nearest Neighbors.\nPelatihan dan Evaluasi Model: Setiap model klasifikasi dilatih pada set pelatihan dan dievaluasi pada set pengujian. Akurasi dari masing-masing model dicatat. \\[\\text{Akurasi} = \\frac{\\text{Jumlah Prediksi Benar}}{\\text{Total Jumlah Prediksi}}\\]\nIdentifikasi Metode Terbaik: Model dengan akurasi tertinggi diidentifikasi sebagai metode terbaik.\nVisualisasi Perbandingan Akurasi: Sebuah diagram batang menunjukkan perbandingan akurasi dari berbagai metode klasifikasi.\n\n\ndata = pd.read_csv(\"garmenBal.csv\")\n\nX = data.drop(columns=['Label'])\ny = data['Label']\n\nwith open(\"scaler_model.pkl\", \"rb\") as scaler_file:\n    scaler = pickle.load(scaler_file)\n\nX_scaled = scaler.transform(X)\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n\nmodels = {\n    'Decision Tree': DecisionTreeClassifier(),\n    'Random Forest': RandomForestClassifier(),\n    'Logistic Regression': LogisticRegression(),\n    'SVM': SVC(),\n    'K-Nearest Neighbors': KNeighborsClassifier()\n}\n\naccuracies = {}\nfor model_name, model in models.items():\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    accuracies[model_name] = accuracy\n\nbest_model = max(accuracies, key=accuracies.get)\nprint(f\"Metode Terbaik: {best_model}\")\nprint(f\"Akurasi Terbaik: {accuracies[best_model]}\")\n\nplt.bar(accuracies.keys(), accuracies.values())\nplt.xlabel('Metode Klasifikasi')\nplt.ylabel('Akurasi')\nplt.title('Perbandingan Akurasi Berbagai Metode Klasifikasi')\nplt.show()\n\nMetode Terbaik: Random Forest\nAkurasi Terbaik: 0.9561586638830898"
  },
  {
    "objectID": "laporan.html#modelling-1",
    "href": "laporan.html#modelling-1",
    "title": "1  Persiapan",
    "section": "5.2 Modelling",
    "text": "5.2 Modelling\nDari perbandingan hasil didapat akurasi random forest adalah yang terbaik jadi dipilihlah random forest untuk langkah modelling.\n\n5.2.1 Random Forest\nRandom Forest adalah algoritma pembelajaran mesin yang digunakan untuk tugas-tugas klasifikasi dan regresi. Algoritma ini bekerja dengan cara membuat banyak pohon keputusan dan menggabungkan hasil mereka. Dengan kata lain, Random Forest membangun banyak pohon keputusan independen dan mengambil rata-rata dari prediksi mereka. Ini membantu untuk mengurangi overfitting, yang merupakan masalah umum dengan pohon keputusan tunggal.\nMisalkan kita memiliki dataset dengan fitur \\(X_1, X_2, ..., X_n\\) dan target \\(Y\\). Untuk setiap pohon dalam hutan, kita akan:\n\nAmbil sampel bootstrap dari data kita (yaitu, sampel dengan penggantian), yang akan digunakan untuk melatih pohon.\nPada setiap node dalam pohon, pilih sejumlah fitur secara acak dan pecahkan node menggunakan fitur yang memberikan penurunan terbesar dalam impuritas (misalnya, Gini impurity atau entropy untuk tugas klasifikasi).\nUlangi langkah-langkah ini sampai kita memiliki jumlah pohon yang diinginkan dalam hutan kita.\n\nUntuk membuat prediksi dengan Random Forest, kita hanya perlu menjalankan setiap pohon pada titik data baru dan mengambil rata-rata (untuk regresi) atau voting mayoritas (untuk klasifikasi) dari prediksi setiap pohon.\nBerikut adalah contoh sederhana bagaimana kita bisa menghitung prediksi menggunakan Random Forest dengan tiga pohon:\nMisalkan kita memiliki tiga pohon keputusan yang masing-masing memberikan prediksi sebagai berikut untuk suatu titik data:\n\nPohon 1: Kelas A\nPohon 2: Kelas B\nPohon 3: Kelas A\n\nDalam hal ini, Random Forest akan memberikan prediksi akhir “Kelas A” karena ini adalah kelas yang paling sering diprediksi oleh pohon-pohon dalam hutan.\n| Pohon | Prediksi |\n|-------|----------|\n| 1     | A        |\n| 2     | B        |\n| 3     | A        |\nPrediksi akhir: A (dipilih oleh mayoritas pohon)\n\n\n5.2.2 Contoh Penerapan\nMisalkan kita memiliki data produktivitas produksi garmen dengan fitur seperti jumlah karyawan, jumlah mesin, dan jam kerja, dan target kita adalah jumlah unit yang diproduksi. Kita bisa menggunakan Random Forest untuk memprediksi jumlah unit yang akan diproduksi berdasarkan fitur-fitur tersebut.\nBerikut adalah contoh bagaimana kita bisa melatih dan menggunakan model Random Forest:\n\nPertama, kita akan melatih model kita menggunakan data historis. Misalkan kita memiliki data berikut:\n\n| Jumlah Karyawan | Jumlah Mesin | Jam Kerja | Unit Diproduksi |\n|-----------------|--------------|-----------|-----------------|\n| 10              | 5            | 8         | 100             |\n| 20              | 10           | 8         | 200             |\n| 30              | 15           | 8         | 300             |\n\nSetelah model kita dilatih, kita bisa menggunakannya untuk memprediksi jumlah unit yang akan diproduksi berdasarkan fitur baru. Misalkan kita memiliki data baru berikut:\n\n| Jumlah Karyawan | Jumlah Mesin | Jam Kerja |\n|-----------------|--------------|-----------|\n| 25              | 12           | 8         |\n\nModel kita mungkin akan memberikan prediksi berikut:\n\n| Jumlah Karyawan | Jumlah Mesin | Jam Kerja | Prediksi Unit Diproduksi |\n|-----------------|--------------|-----------|--------------------------|\n| 25              | 12           | 8         | 250                      |\nDalam contoh ini, model kita memprediksi bahwa dengan 25 karyawan, 12 mesin, dan 8 jam kerja, kita akan dapat memproduksi 250 unit. Harap dicatat bahwa ini hanyalah contoh sederhana dan dalam praktiknya, model Random Forest akan melibatkan banyak pohon keputusan dan mungkin fitur yang lebih kompleks. Selain itu, penting untuk melakukan validasi silang dan penyetelan hyperparameter untuk memastikan bahwa model kita tidak overfitting dan dapat memprediksi dengan baik pada data yang belum pernah dilihat sebelumnya.\n\n\n5.2.3 Code Modelling\nPemodelan Random Forest untuk Klasifikasi\n\nPembacaan Data:\n\nData dibaca dari file “garmenBal.csv”.\n\nPemisahan Fitur dan Label:\n\nFitur-fitur disimpan dalam variabel (X).\nLabel disimpan dalam variabel (y).\n\nPemulihan Model Scaler:\n\nModel scaler (MinMaxScaler) yang telah disimpan sebelumnya dibaca kembali.\n\nNormalisasi Fitur:\n\nFitur-fitur dinormalisasi menggunakan model scaler.\n\nIterasi untuk Memilih Model Terbaik:\n\nDilakukan iterasi untuk setiap nilai (n_estimators) dari 1 hingga 100.\nSebuah model Random Forest dibangun dengan jumlah pohon ((n_estimators)) tertentu.\nModel tersebut dilatih pada data yang dinormalisasi.\nHasil prediksi dibandingkan dengan label sebenarnya untuk menghitung akurasi.\nJika akurasi model saat ini lebih baik daripada yang sebelumnya terbaik, model tersebut dianggap sebagai model terbaik.\n\nPenyimpanan Model Terbaik:\n\nModel Random Forest dengan akurasi tertinggi selama iterasi disimpan ke dalam file ‘best_rf_model.pkl’ menggunakan modul pickle.\n\n\nKode ini bertujuan untuk mencari model Random Forest dengan jumlah pohon terbaik yang memberikan akurasi tertinggi pada data yang telah diimbangi dan dinormalisasi. Model terbaik tersebut kemudian disimpan untuk penggunaan lebih lanjut.\n\ndata = pd.read_csv(\"garmenBal.csv\")\n\nX = data.drop('Label', axis=1)\ny = data['Label']\n\nwith open('scaler_model.pkl', 'rb') as file:\n    scaler = pickle.load(file)\n\nX_normalized = scaler.transform(X)\n\nbest_accuracy = 0.0\nbest_rf_model = None\n\nfor n_estimators in range(1, 101):\n    rf_model = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n    rf_model.fit(X_normalized, y)\n\n    y_pred = rf_model.predict(X_normalized)\n\n    accuracy = accuracy_score(y, y_pred)\n\n    if accuracy &gt; best_accuracy:\n        best_accuracy = accuracy\n        best_rf_model = rf_model\n\nprint(f\"Akurasi terbaik: {best_accuracy:.2%} dengan {best_rf_model.n_estimators}.\")\n\nwith open('best_rf_model.pkl', 'wb') as file:\n    pickle.dump(best_rf_model, file)\n\nAkurasi terbaik: 100.00% dengan 53."
  },
  {
    "objectID": "laporan.html#prediksi-sebelum-streamlit",
    "href": "laporan.html#prediksi-sebelum-streamlit",
    "title": "1  Persiapan",
    "section": "6.1 Prediksi (Sebelum Streamlit)",
    "text": "6.1 Prediksi (Sebelum Streamlit)\nSebelum dimplementasikan kedalam aplikasi streamlit kita buat prediksi melalui editor terlebih dahulu.\nDalam kode tersebut, dilakukan implementasi untuk memprediksi kelas output (Label) berdasarkan masukan (input) yang diberikan oleh pengguna. Berikut adalah penjelasan langkah-langkahnya:\n\nPembacaan Model dan Scaler:\n\nModel Random Forest (best_rf_model.pkl) dan objek scaler (scaler_model.pkl) dibaca dari file menggunakan modul pickle.\n\nInput dari Pengguna:\n\nPengguna diminta untuk memasukkan nilai-nilai berikut:\n\nSMV (Standard Minute Value)\nWIP (Work in Progress)\nOver Time\nIncentive\nIdle Time\nIdle Men\nNumber of Workers\n\n\nPembentukan Data Input:\n\nInput pengguna disusun ke dalam bentuk dictionary input_data.\nDictionary tersebut kemudian diubah menjadi DataFrame input_df.\n\nNormalisasi Data Input:\n\nData input dinormalisasi menggunakan model scaler yang telah dibaca sebelumnya (scaler).\n\nPrediksi dengan Model Random Forest:\n\nModel Random Forest (rf_model) digunakan untuk melakukan prediksi pada data input yang telah dinormalisasi (X_normalized).\nHasil prediksi disimpan dalam variabel prediction.\n\nOutput Hasil Prediksi:\n\nHasil prediksi ditampilkan kepada pengguna.\n\n\n\nwith open('scaler_model.pkl', 'rb') as file:\n    scaler = pickle.load(file)\n\nwith open('best_rf_model.pkl', 'rb') as file:\n    rf_model = pickle.load(file)\n\nsmv = float(input(\"Masukkan SMV (Standard Minute Value): \"))\nwip = float(input(\"Masukkan Work in Progress (WIP): \"))\nover_time = float(input(\"Masukkan Over Time: \"))\nincentive = float(input(\"Masukkan Incentive: \"))\nidle_time = float(input(\"Masukkan Idle Time: \"))\nidle_men = float(input(\"Masukkan Idle Men: \"))\nno_of_workers = int(input(\"Masukkan Number of Workers: \"))\n\ninput_data = {\n    'smv': smv,\n    'wip': wip,\n    'over_time': over_time,\n    'incentive': incentive,\n    'idle_time': idle_time,\n    'idle_men': idle_men,\n    'no_of_workers': no_of_workers\n}\n\ninput_df = pd.DataFrame([input_data])\nX_normalized = scaler.transform(input_df)\n\nprediction = rf_model.predict(X_normalized)\n\nprint(\"Hasil Prediksi:\", prediction[0])\n\nMasukkan SMV (Standard Minute Value): 26.2\nMasukkan Work in Progress (WIP): 1108\nMasukkan Over Time: 7080\nMasukkan Incentive: 98\nMasukkan Idle Time: 0\nMasukkan Idle Men: 0\nMasukkan Number of Workers: 58\nHasil Prediksi: High"
  },
  {
    "objectID": "laporan.html#implementasi-streamlit",
    "href": "laporan.html#implementasi-streamlit",
    "title": "1  Persiapan",
    "section": "6.2 Implementasi Streamlit",
    "text": "6.2 Implementasi Streamlit\nPada implementasi dengan menggunakan streamlit kita buat file python yang berisi code diatas dengan mengubah kode menjadi format yang sesuai dengan Streamlit, perlu membuat aplikasi Streamlit yang menampilkan formulir input untuk fitur-fitur yang diperlukan dan menampilkan hasil prediksi. Berikut kode yang sudah bisa dijalankan di streamlit:\n\nimport streamlit as st\nimport pickle\nimport pandas as pd\n\nwith open(\"scaler_model.pkl\", \"rb\") as scaler_file:\n    scaler = pickle.load(scaler_file)\n\nwith open(\"best_rf_model.pkl\", \"rb\") as model_file:\n    rf_model = pickle.load(model_file)\n\nst.title(\"Aplikasi Prediksi Produktivitas Karyawan\")\n\nst.header(\"Masukkan Nilai Fitur\")\n\nsmv = st.number_input(\"SMV (Nilai Menit Standar):\", value=0.0, step=0.1, format=\"%.1f\", help=\"Nilai menit standar yang dialokasikan untuk tugas.\")\nwip = st.number_input(\"Work in Progress (WIP):\", value=0, step=1, help=\"Jumlah barang setengah jadi atau belum selesai dalam produksi.\")\nover_time = st.number_input(\"Over Time (Lembur) (dalam menit):\", value=0, step=30, help=\"Jumlah waktu tambahan yang dihabiskan dalam produksi di atas waktu kerja reguler dalam menit.\")\nincentive = st.number_input(\"Insentif (dalam BDT):\", value=0, step=100, help=\"Jumlah insentif finansial yang diberikan sebagai motivasi untuk meningkatkan produktivitas.\")\nidle_time = st.number_input(\"Waktu Tidak Efisien (dalam menit):\", value=0, step=30, help=\"Jumlah waktu ketika produksi terhenti atau tidak efisien karena berbagai alasan.\")\nidle_men = st.number_input(\"Pekerja Tidak Efisien (Jumlah Pekerja):\", value=0, step=1, help=\"Jumlah pekerja yang menjadi tidak efisien atau tidak dapat bekerja selama produksi terhenti atau tidak efisien.\")\nno_of_workers = st.number_input(\"Jumlah Pekerja:\", value=0, step=1, help=\"Jumlah total pekerja yang bekerja selama periode produksi.\")\n\nif st.button(\"Prediksi Produktivitas\"):\n    input_data = {\n        'smv': smv,\n        'wip': wip,\n        'over_time': over_time,\n        'incentive': incentive,\n        'idle_time': idle_time,\n        'idle_men': idle_men,\n        'no_of_workers': no_of_workers\n    }\n    input_df = pd.DataFrame([input_data])\n    X_normalized = scaler.transform(input_df)\n\n    prediction = rf_model.predict(X_normalized)\n\n    label_produk = ''\n    if prediction[0] == 'High':\n        label_produk = 'Tinggi'\n    elif prediction[0] == 'Medium':\n        label_produk = 'Sedang'\n    elif prediction[0] == 'Low':\n        label_produk = 'Rendah'\n\n    st.write(f\"Hasil Prediksi Produktivitas: {label_produk}\")\n\nst.subheader(\"Grafik Input Pengguna\")\ndata = pd.DataFrame({'Fitur': ['SMV', 'WIP', 'Over Time', 'Insentif', 'Waktu Tidak Efisien', 'Pekerja Tidak Efisien', 'Jumlah Pekerja'],\n                     'Nilai': [smv, wip, over_time, incentive, idle_time, idle_men, no_of_workers]})\nst.bar_chart(data.set_index('Fitur'))\n\nDalam kode di atas, kita menggunakan Streamlit untuk membuat formulir input dengan elemen-elemen input numerik. Saat tombol “Predict” ditekan, nilai-nilai input diambil, diubah menjadi DataFrame, dinormalisasi menggunakan model scaler, dan kemudian digunakan untuk melakukan prediksi dengan model Random Forest. Hasil prediksi kemudian ditampilkan kepada pengguna."
  },
  {
    "objectID": "laporan.html#tampilan-strealit",
    "href": "laporan.html#tampilan-strealit",
    "title": "1  Persiapan",
    "section": "6.3 Tampilan Strealit",
    "text": "6.3 Tampilan Strealit\n\n\n\nCuplikan layar 2023-11-15 173532.png"
  }
]